Bien s√ªr‚ÄØ! Voici une version mieux pr√©sent√©e et corrig√©e de ton README en Markdown, en gardant un style naturel (majuscules seulement au d√©but des titres et des phrases) et en structurant mieux les blocs de code et les sections :

# AugmentedSocialScientist enhancements

## About this fork

this repository is a thin fork of [rubingshen/AugmentedSocialScientist](https://github.com/rubingshen/AugmentedSocialScientist) with three main improvements:
- adaptive training strategy for difficult labels (class 1 f1-score < 0.5)
- automatic oversampling of the minority class in memory
- native GPU detection on macOS (mps) as well as CUDA

## New features

### adaptive training for low-f1 tasks

if your previous model‚Äôs f1-score on the positive class is below 0.5, the training script will automatically:
1. increase the batch size (64 instead of 32)
2. lower the learning rate (1e-5 instead of 5e-5)
3. apply a class-weighted loss (`pos_weight = n_neg / n_pos`)
4. oversample the positive examples in memory until they roughly match the number of negatives
5. train for an extended number of epochs (15 instead of the recorded best epoch)

if f1 ‚â• 0.5, the original defaults are kept:
- batch size = 32
- learning rate = 5e-5
- no class weighting
- no oversampling
- epochs = best_epoch from your metrics csv (or 10 if missing)

### improved gpu detection

in `BertBase.__init__` (and `CamembertBase` alike), we now detect the available device as follows:

python
if torch.cuda.is_available():
    device = torch.device("cuda")
elif torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")

macOS users on Apple silicon will see:

mps is available. using the Apple Silicon GPU!

Installation

you can install directly from this repository:

pip install git+https://github.com/yourusername/AugmentedSocialScientist.git

or clone it and install in editable mode:

git clone https://github.com/yourusername/AugmentedSocialScientist.git
cd AugmentedSocialScientist
pip install -e .

Usage

from AugmentedSocialScientist.bert_base import BertBase
import torch

# load your data
train_texts, train_labels = [...], [...]
val_texts, val_labels     = [...], [...]

# instantiate the model (cuda, mps, or cpu auto-detection)
model = BertBase(model_name="bert-base-cased")

# decide hyperparameters based on previous f1 score
prev_f1 = 0.42
if prev_f1 < 0.5:
    batch_size = 64
    lr         = 1e-5
    pos_weight = torch.tensor([n_neg/n_pos], device=model.device)
    n_epochs   = 15
else:
    batch_size = 32
    lr         = 5e-5
    pos_weight = None
    n_epochs   = your_best_epoch

# prepare dataloaders
train_loader = model.encode(train_texts, train_labels, batch_size=batch_size)
val_loader   = model.encode(val_texts,   val_labels,   batch_size=batch_size)

# train and save the model
scores = model.run_training(
    train_loader,
    val_loader,
    n_epochs=n_epochs,
    lr=lr,
    pos_weight=pos_weight,
    save_model_as="my_model_name"
)
print("precision, recall, f1, support:", scores)

# after training, the model is saved under ./models/my_model_name/
# you can reload and use it like this:

from AugmentedSocialScientist.bert_base import BertBase

model = BertBase(model_name="bert-base-cased")
trained_model = model.load_model("./models/my_model_name")
predictions = model.predict_with_model(val_loader, "./models/my_model_name")

License

same as the original project (MIT license).

---

Veux-tu aussi que je te propose une version encore un peu plus "pro" pour un d√©p√¥t GitHub public, avec un sommaire cliquable (`[toc]`), un badge de licence, etc.? üöÄ  
Cela donnerait encore plus de s√©rieux √† ton fork si tu veux le publier proprement !